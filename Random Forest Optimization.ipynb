{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest 1 : all variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inputs:\n",
    "t_data  = pd.read_csv('data/t_dummies')\n",
    "p_data = pd.read_csv('data/p_dummies')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rmse_train:231.51117855204245\n",
      "rmse_test:564.7473694670788\n",
      "rmse_global:326.59739573309764\n"
     ]
    }
   ],
   "source": [
    "# Import Model specific modules\n",
    "\n",
    "# Calling Scaler\n",
    "sc = StandardScaler()\n",
    "\n",
    "# X and Y & Scalling\n",
    "y = t_data['price']\n",
    "X = sc.fit_transform(t_data.drop(columns=['price','id']))\n",
    "\n",
    "# 1. Train-Test Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = .20, random_state=1)\n",
    "\n",
    "# Fitting & Predicting in Train \n",
    "regressor = RandomForestRegressor(n_estimators=20, random_state=0)\n",
    "regressor.fit(X_train, y_train)\n",
    "\n",
    "# Predicting in Train\n",
    "train_y_pred = regressor.predict(X_train)\n",
    "test_y_pred = regressor.predict(X_test)\n",
    "global_y_pred = regressor.predict(X)\n",
    "\n",
    "# Evaluating Train Prediction\n",
    "rmse_train = mean_squared_error(y_true= y_train, y_pred= train_y_pred, squared=False)\n",
    "print(f'rmse_train:{rmse_train}')\n",
    "\n",
    "rmse_test = mean_squared_error(y_true= y_test, y_pred= test_y_pred, squared=False)\n",
    "print(f'rmse_test:{rmse_test}')\n",
    "\n",
    "rmse_global = mean_squared_error(y_true= y, y_pred= global_y_pred, squared=False)\n",
    "print(f'rmse_global:{rmse_global}')\n",
    "\n",
    "\n",
    "# Generating output on predict.csv_data\n",
    "regressor.fit(X, y)\n",
    "regressor.fit(X, y)\n",
    "\n",
    "X = sc.fit_transform(p_data.drop(columns=['id']))\n",
    "y_pred = regressor.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output1\n",
    "output1 = pd.DataFrame(y_pred)\n",
    "output1.rename(columns={0:'price'}, inplace=True)\n",
    "output1.index.names = ['id']\n",
    "output1.to_csv('output/output1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_data  = pd.read_csv('data/t_dummies')\n",
    "p_data = pd.read_csv('data/p_dummies')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest 2 : Removing x to reduce colinearity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_data  = pd.read_csv('data/t_dummies_col')\n",
    "p_data = pd.read_csv('data/p_dummies_col')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rmse_train:229.67828909209354\n",
      "rmse_test:564.4036460562791\n",
      "rmse_global:325.4412209916582\n"
     ]
    }
   ],
   "source": [
    "# Import Model specific modules\n",
    "\n",
    "# Calling Scaler\n",
    "sc = StandardScaler()\n",
    "\n",
    "# X and Y & Scalling\n",
    "y = t_data['price']\n",
    "X = sc.fit_transform(t_data.drop(columns=['price','id']))\n",
    "\n",
    "# 1. Train-Test Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = .20, random_state=1)\n",
    "\n",
    "# Fitting & Predicting in Train \n",
    "regressor = RandomForestRegressor(n_estimators=20, random_state=0)\n",
    "regressor.fit(X_train, y_train)\n",
    "\n",
    "# Predicting in Train\n",
    "train_y_pred = regressor.predict(X_train)\n",
    "test_y_pred = regressor.predict(X_test)\n",
    "global_y_pred = regressor.predict(X)\n",
    "\n",
    "# Evaluating Train Prediction\n",
    "rmse_train = mean_squared_error(y_true= y_train, y_pred= train_y_pred, squared=False)\n",
    "print(f'rmse_train:{rmse_train}')\n",
    "\n",
    "rmse_test = mean_squared_error(y_true= y_test, y_pred= test_y_pred, squared=False)\n",
    "print(f'rmse_test:{rmse_test}')\n",
    "\n",
    "rmse_global = mean_squared_error(y_true= y, y_pred= global_y_pred, squared=False)\n",
    "print(f'rmse_global:{rmse_global}')\n",
    "\n",
    "\n",
    "# Generating output on predict.csv_data\n",
    "regressor.fit(X, y)\n",
    "regressor.fit(X, y)\n",
    "\n",
    "X = sc.fit_transform(p_data.drop(columns=['id']))\n",
    "y_pred = regressor.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output2\n",
    "output2 = pd.DataFrame(y_pred)\n",
    "output2.rename(columns={0:'price'}, inplace=True)\n",
    "output2.index.names = ['id']\n",
    "output2.to_csv('output/output2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest 3: Removing X and Z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_data  = pd.read_csv('data/t_dummies_col')\n",
    "p_data = pd.read_csv('data/p_dummies_col')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rmse_train:292.4195697763558\n",
      "rmse_test:560.8203094032219\n",
      "rmse_global:329.2613804939887\n"
     ]
    }
   ],
   "source": [
    "# Import Model specific modules\n",
    "\n",
    "# Calling Scaler\n",
    "sc = StandardScaler()\n",
    "\n",
    "# X and Y & Scalling\n",
    "y = t_data['price']\n",
    "X = sc.fit_transform(t_data.drop(columns=['price','id','z']))\n",
    "\n",
    "# 1. Train-Test Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = .10, random_state=1)\n",
    "\n",
    "# Fitting & Predicting in Train \n",
    "regressor = RandomForestRegressor(n_estimators=20, random_state=0, max_depth= 17)\n",
    "regressor.fit(X_train, y_train)\n",
    "\n",
    "# Predicting in Train\n",
    "train_y_pred = regressor.predict(X_train)\n",
    "test_y_pred = regressor.predict(X_test)\n",
    "global_y_pred = regressor.predict(X)\n",
    "\n",
    "# Evaluating Train Prediction\n",
    "rmse_train = mean_squared_error(y_true= y_train, y_pred= train_y_pred, squared=False)\n",
    "print(f'rmse_train:{rmse_train}')\n",
    "\n",
    "rmse_test = mean_squared_error(y_true= y_test, y_pred= test_y_pred, squared=False)\n",
    "print(f'rmse_test:{rmse_test}')\n",
    "\n",
    "rmse_global = mean_squared_error(y_true= y, y_pred= global_y_pred, squared=False)\n",
    "print(f'rmse_global:{rmse_global}')\n",
    "\n",
    "\n",
    "# Generating output on predict.csv_data\n",
    "regressor.fit(X, y)\n",
    "regressor.fit(X, y)\n",
    "\n",
    "X = sc.fit_transform(p_data.drop(columns=['id','z']))\n",
    "y_pred = regressor.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output2\n",
    "output3 = pd.DataFrame(y_pred)\n",
    "output3.rename(columns={0:'price'}, inplace=True)\n",
    "output3.index.names = ['id']\n",
    "output3.to_csv('output/output3')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adjusting Max Depth params manually for a ready to go solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n",
      "rmse_train:487.77304961915166\n",
      "rmse_test:584.0538483347638\n",
      "rmse_global:498.24036203716764\n",
      "13\n",
      "rmse_train:432.8154082809027\n",
      "rmse_test:569.0211583791322\n",
      "rmse_global:448.30397529332674\n",
      "14\n",
      "rmse_train:388.51590103787424\n",
      "rmse_test:559.2782995943667\n",
      "rmse_global:408.8170334077544\n",
      "15\n",
      "rmse_train:350.48946890796566\n",
      "rmse_test:558.8091483822353\n",
      "rmse_global:376.5470603317221\n",
      "16\n",
      "rmse_train:318.4466450158363\n",
      "rmse_test:560.715758405345\n",
      "rmse_global:350.30028233119447\n",
      "17\n",
      "rmse_train:292.4195697763558\n",
      "rmse_test:560.8203094032219\n",
      "rmse_global:329.2613804939887\n",
      "18\n",
      "rmse_train:271.3485152803008\n",
      "rmse_test:567.2727278572232\n",
      "rmse_global:313.7672976299009\n",
      "19\n",
      "rmse_train:255.91280188081112\n",
      "rmse_test:562.4727587425901\n",
      "rmse_global:300.9699107290037\n"
     ]
    }
   ],
   "source": [
    "# Import Model specific modules\n",
    "\n",
    "\n",
    "for depth in list(range(12,20)):\n",
    "    print(depth)\n",
    "# Calling Scaler\n",
    "    sc = StandardScaler()\n",
    "\n",
    "# X and Y & Scalling\n",
    "    y = t_data['price']\n",
    "    X = sc.fit_transform(t_data.drop(columns=['price','id','z']))\n",
    "\n",
    "# 1. Train-Test Split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = .10, random_state=1)\n",
    "\n",
    "# Fitting & Predicting in Train \n",
    "    regressor = RandomForestRegressor(n_estimators=20, random_state=0, max_depth= depth)\n",
    "    regressor.fit(X_train, y_train)\n",
    "\n",
    "# Predicting in Train\n",
    "    train_y_pred = regressor.predict(X_train)\n",
    "    test_y_pred = regressor.predict(X_test)\n",
    "    global_y_pred = regressor.predict(X)\n",
    "\n",
    "# Evaluating Train Prediction\n",
    "    rmse_train = mean_squared_error(y_true= y_train, y_pred= train_y_pred, squared=False)\n",
    "    print(f'rmse_train:{rmse_train}')\n",
    "\n",
    "    rmse_test = mean_squared_error(y_true= y_test, y_pred= test_y_pred, squared=False)\n",
    "    print(f'rmse_test:{rmse_test}')\n",
    "\n",
    "    rmse_global = mean_squared_error(y_true= y, y_pred= global_y_pred, squared=False)\n",
    "    print(f'rmse_global:{rmse_global}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from pprint import pprint\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of trees in random forest\n",
    "n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]\n",
    "# Number of features to consider at every split\n",
    "max_features = ['auto', 'sqrt']\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
    "max_depth.append(None)\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [2, 5, 10]\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "# Method of selecting samples for training each tree\n",
    "bootstrap = [True, False]\n",
    "# Create the random grid\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine Tuning Random Forest Params "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10,\n",
       "             estimator=RandomForestRegressor(max_depth=19, n_estimators=20,\n",
       "                                             random_state=0),\n",
       "             param_grid=[{'bootstrap': [True, False],\n",
       "                          'max_depth': [10, 50, None], 'max_features': [5, 10],\n",
       "                          'n_estimators': [10, 25]}],\n",
       "             scoring='neg_mean_squared_error')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = [\n",
    "{'n_estimators': [10, 25], 'max_features': [5, 10], \n",
    " 'max_depth': [10, 50, None], 'bootstrap': [True, False]}\n",
    "]\n",
    "\n",
    "grid_search_forest = GridSearchCV(regressor, param_grid, cv=10, scoring='neg_mean_squared_error')\n",
    "grid_search_forest.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "850.5680434062261 {'bootstrap': True, 'max_depth': 10, 'max_features': 5, 'n_estimators': 10}\n",
      "835.2736700981227 {'bootstrap': True, 'max_depth': 10, 'max_features': 5, 'n_estimators': 25}\n",
      "713.3625832461244 {'bootstrap': True, 'max_depth': 10, 'max_features': 10, 'n_estimators': 10}\n",
      "704.3944250165373 {'bootstrap': True, 'max_depth': 10, 'max_features': 10, 'n_estimators': 25}\n",
      "638.1479115277159 {'bootstrap': True, 'max_depth': 50, 'max_features': 5, 'n_estimators': 10}\n",
      "608.6540379687269 {'bootstrap': True, 'max_depth': 50, 'max_features': 5, 'n_estimators': 25}\n",
      "598.5004356355074 {'bootstrap': True, 'max_depth': 50, 'max_features': 10, 'n_estimators': 10}\n",
      "575.4670695632499 {'bootstrap': True, 'max_depth': 50, 'max_features': 10, 'n_estimators': 25}\n",
      "638.1479115277159 {'bootstrap': True, 'max_depth': None, 'max_features': 5, 'n_estimators': 10}\n",
      "608.6540379687269 {'bootstrap': True, 'max_depth': None, 'max_features': 5, 'n_estimators': 25}\n",
      "598.5004356355074 {'bootstrap': True, 'max_depth': None, 'max_features': 10, 'n_estimators': 10}\n",
      "575.4670695632499 {'bootstrap': True, 'max_depth': None, 'max_features': 10, 'n_estimators': 25}\n",
      "843.2755300303187 {'bootstrap': False, 'max_depth': 10, 'max_features': 5, 'n_estimators': 10}\n",
      "825.2904854992486 {'bootstrap': False, 'max_depth': 10, 'max_features': 5, 'n_estimators': 25}\n",
      "715.6524891645595 {'bootstrap': False, 'max_depth': 10, 'max_features': 10, 'n_estimators': 10}\n",
      "704.1094682640318 {'bootstrap': False, 'max_depth': 10, 'max_features': 10, 'n_estimators': 25}\n",
      "622.0196624556958 {'bootstrap': False, 'max_depth': 50, 'max_features': 5, 'n_estimators': 10}\n",
      "596.253602321667 {'bootstrap': False, 'max_depth': 50, 'max_features': 5, 'n_estimators': 25}\n",
      "585.9415034874517 {'bootstrap': False, 'max_depth': 50, 'max_features': 10, 'n_estimators': 10}\n",
      "572.5904693531431 {'bootstrap': False, 'max_depth': 50, 'max_features': 10, 'n_estimators': 25}\n",
      "622.0196624556958 {'bootstrap': False, 'max_depth': None, 'max_features': 5, 'n_estimators': 10}\n",
      "596.253602321667 {'bootstrap': False, 'max_depth': None, 'max_features': 5, 'n_estimators': 25}\n",
      "585.9415034874517 {'bootstrap': False, 'max_depth': None, 'max_features': 10, 'n_estimators': 10}\n",
      "572.5904693531431 {'bootstrap': False, 'max_depth': None, 'max_features': 10, 'n_estimators': 25}\n"
     ]
    }
   ],
   "source": [
    "cvres = grid_search_forest.cv_results_\n",
    "for mean_score, params in zip(cvres[\"mean_test_score\"], cvres[\"params\"]):\n",
    "    print(np.sqrt(-mean_score), params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=False, max_depth=50, max_features=10,\n",
       "                      n_estimators=25, random_state=0)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search_forest.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid_Search Fine Tunned Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rmse_train:0.1340485272688229\n",
      "rmse_test:555.4732797694369\n",
      "rmse_global:175.6669750668043\n"
     ]
    }
   ],
   "source": [
    "# Import Model specific modules\n",
    "\n",
    "# Calling Scaler\n",
    "sc = StandardScaler()\n",
    "\n",
    "# X and Y & Scalling\n",
    "y = t_data['price']\n",
    "X = sc.fit_transform(t_data.drop(columns=['price','id','z']))\n",
    "\n",
    "# 1. Train-Test Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = .10, random_state=1)\n",
    "\n",
    "# Fitting & Predicting in Train \n",
    "regressor = RandomForestRegressor(bootstrap=False, max_depth=50, max_features=10,\n",
    "                      n_estimators=25, random_state=25)\n",
    "regressor.fit(X_train, y_train)\n",
    "\n",
    "# Predicting in Train\n",
    "train_y_pred = regressor.predict(X_train)\n",
    "test_y_pred = regressor.predict(X_test)\n",
    "global_y_pred = regressor.predict(X)\n",
    "\n",
    "# Evaluating Train Prediction\n",
    "rmse_train = mean_squared_error(y_true= y_train, y_pred= train_y_pred, squared=False)\n",
    "print(f'rmse_train:{rmse_train}')\n",
    "\n",
    "rmse_test = mean_squared_error(y_true= y_test, y_pred= test_y_pred, squared=False)\n",
    "print(f'rmse_test:{rmse_test}')\n",
    "\n",
    "rmse_global = mean_squared_error(y_true= y, y_pred= global_y_pred, squared=False)\n",
    "print(f'rmse_global:{rmse_global}')\n",
    "\n",
    "\n",
    "# Generating output on predict.csv_data\n",
    "regressor.fit(X, y)\n",
    "regressor.fit(X, y)\n",
    "\n",
    "X = sc.fit_transform(p_data.drop(columns=['id','z']))\n",
    "y_pred = regressor.predict(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fintuned Model Adding Bootstrap to reduce overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rmse_train:207.07553282722475\n",
      "rmse_test:536.3612946133123\n",
      "rmse_global:259.54502138376955\n"
     ]
    }
   ],
   "source": [
    "# Import Model specific modules\n",
    "\n",
    "# Calling Scaler\n",
    "sc = StandardScaler()\n",
    "\n",
    "# X and Y & Scalling\n",
    "y = t_data['price']\n",
    "X = sc.fit_transform(t_data.drop(columns=['price','id','z']))\n",
    "\n",
    "# 1. Train-Test Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = .10, random_state=1)\n",
    "\n",
    "# Fitting & Predicting in Train \n",
    "regressor = RandomForestRegressor(bootstrap=True, max_depth=50, max_features=10,\n",
    "                      n_estimators=150, random_state=13)\n",
    "regressor.fit(X_train, y_train)\n",
    "# Output2\n",
    "output3 = pd.DataFrame(y_pred)\n",
    "output3.rename(columns={0:'price'}, inplace=True)\n",
    "output3.index.names = ['id']\n",
    "output3.to_csv('output/output2')\n",
    "# Predicting in Train\n",
    "train_y_pred = regressor.predict(X_train)\n",
    "test_y_pred = regressor.predict(X_test)\n",
    "global_y_pred = regressor.predict(X)\n",
    "\n",
    "# Evaluating Train Prediction\n",
    "rmse_train = mean_squared_error(y_true= y_train, y_pred= train_y_pred, squared=False)\n",
    "print(f'rmse_train:{rmse_train}')\n",
    "\n",
    "rmse_test = mean_squared_error(y_true= y_test, y_pred= test_y_pred, squared=False)\n",
    "print(f'rmse_test:{rmse_test}')\n",
    "\n",
    "rmse_global = mean_squared_error(y_true= y, y_pred= global_y_pred, squared=False)\n",
    "print(f'rmse_global:{rmse_global}')\n",
    "\n",
    "\n",
    "# Generating output on predict.csv_data\n",
    "\n",
    "# Fitting the model with all training data\n",
    "regressor.fit(X, y)\n",
    "regressor.fit(X, y)\n",
    "\n",
    "X = sc.fit_transform(p_data.drop(columns=['id','z']))\n",
    "y_pred = regressor.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output2\n",
    "output4 = pd.DataFrame(y_pred)\n",
    "output4.rename(columns={0:'price'}, inplace=True)\n",
    "output4.index.names = ['id']\n",
    "output4.to_csv('output/output4')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploring optimization around fintuned model to reduce overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rmse_train:204.62164241188577\n",
      "rmse_test:535.5286981092925\n",
      "rmse_global:257.61432533531\n"
     ]
    }
   ],
   "source": [
    "# Import Model specific modules\n",
    "\n",
    "# Calling Scaler\n",
    "sc = StandardScaler()\n",
    "\n",
    "# X and Y & Scalling\n",
    "y = t_data['price']\n",
    "X = sc.fit_transform(t_data.drop(columns=['price','id','z']))\n",
    "\n",
    "# 1. Train-Test Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = .10, random_state=1)\n",
    "\n",
    "# Fitting & Predicting in Train \n",
    "regressor = RandomForestRegressor(bootstrap=True, max_depth=30, max_features=10,\n",
    "                      n_estimators=500, random_state=13)\n",
    "regressor.fit(X_train, y_train)\n",
    "# Output2\n",
    "output3 = pd.DataFrame(y_pred)\n",
    "output3.rename(columns={0:'price'}, inplace=True)\n",
    "output3.index.names = ['id']\n",
    "output3.to_csv('output/output2')\n",
    "# Predicting in Train\n",
    "train_y_pred = regressor.predict(X_train)\n",
    "test_y_pred = regressor.predict(X_test)\n",
    "global_y_pred = regressor.predict(X)\n",
    "\n",
    "# Evaluating Train Prediction\n",
    "rmse_train = mean_squared_error(y_true= y_train, y_pred= train_y_pred, squared=False)\n",
    "print(f'rmse_train:{rmse_train}')\n",
    "\n",
    "rmse_test = mean_squared_error(y_true= y_test, y_pred= test_y_pred, squared=False)\n",
    "print(f'rmse_test:{rmse_test}')\n",
    "\n",
    "rmse_global = mean_squared_error(y_true= y, y_pred= global_y_pred, squared=False)\n",
    "print(f'rmse_global:{rmse_global}')\n",
    "\n",
    "\n",
    "# Generating output on predict.csv_data\n",
    "\n",
    "# Fitting the model with all training data\n",
    "regressor.fit(X, y)\n",
    "regressor.fit(X, y)\n",
    "\n",
    "X = sc.fit_transform(p_data.drop(columns=['id','z']))\n",
    "y_pred = regressor.predict(X)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output5\n",
    "output5 = pd.DataFrame(y_pred)\n",
    "output5.rename(columns={0:'price'}, inplace=True)\n",
    "output5.index.names = ['id']\n",
    "output5.to_csv('output/output5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
